# Loading Config for Token Optimization & Perf

## Core Config (Always Load)
```yaml
Core:
  Always: [CLAUDE.md, RULES.md, PERSONAS.md, MCP.md]
  Priority: Critical behavioral rules, personas & MCP patterns
  Size: ~4600 tokens
  Reason: Essential for all Claude Code behavior, personas globally available
  
Global Availability:
  PERSONAS.md: All 9 cognitive archetypes available via /persona:
  MCP.md: All MCP patterns available automatically
  
Commands:
  Trigger: /user:
  Path: .claude/commands/
  Size: ~50 tokens per command
  Cache: Most recent 5 commands
  Index: command names & risk levels only
  
SharedResources:
  LoadWith: Associated commands
  Path: .claude/commands/shared/
  Size: ~150 tokens per YAML
  Examples:
    - cleanup-patterns.yml→loads w/ /user:cleanup
    - git-workflow.yml→loads w/ git ops
    - planning-mode.yml→loads w/ risky commands
```

## Advanced Loading Optimization
```yaml
Smart Loading Strategies:
  Predictive: Anticipate likely-needed resources based on command patterns
  Contextual: Load resources based on project type and user behavior
  Lazy: Defer loading non-critical resources until explicitly needed
  Incremental: Load minimal first, expand as complexity increases
  
Intelligent Caching:
  Command Frequency: Cache most-used commands permanently
  Workflow Patterns: Preload resources for common command sequences
  User Preferences: Remember and preload user's preferred tools
  Session Context: Keep relevant context across related operations
  
Token Efficiency:
  Base load: 4600 tokens (CLAUDE.md + RULES.md + PERSONAS.md + MCP.md)
  Optimized commands: 4650-4700 tokens (~50 tokens per command)
  Smart shared resources: Load only when needed, avg 150-300 tokens
  Performance gain: ~20-30% reduction through intelligent loading
  Trade-off: Higher base load for consistent global functionality
  
Context Compression:
  Auto UltraCompressed: Enable when context approaches limits
  Selective Detail: Keep summaries, load detail on demand
  Result Caching: Store and reuse expensive analysis results
  Pattern Recognition: Learn and optimize based on usage patterns
```

## Performance Monitoring Integration
```yaml
Loading Metrics:
  Time to Load: Track component loading speed
  Cache Hit Rate: Measure effectiveness of caching strategies
  Memory Usage: Monitor total context size and optimization opportunities
  User Satisfaction: Track command completion success rates
  
Adaptive Optimization:
  Slow Loading: Automatically switch to lighter alternatives
  High Memory: Trigger context compression and cleanup
  Cache Misses: Adjust caching strategy based on usage patterns
  Performance Degradation: Fall back to minimal loading mode
```